{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  #disables GPU \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#tf.__version__\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = VGG16(weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=(224, 224, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_path,img_shape, preprocess=True):\n",
    "    \n",
    "    img_rows=img_shape[0]\n",
    "    img_cols=img_shape[1]\n",
    "    #num_channel=img_shape[2]\n",
    "\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(img_rows, img_cols))    \n",
    "    if preprocess:\n",
    "        img = image.img_to_array(img) \n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        img =  preprocess_input(img)\n",
    "        return img\n",
    "\n",
    "    #data = np.array(data)\n",
    "    #data = data.astype('float32')\n",
    "    #data /= 255\n",
    "    #labels=np.array(labels)\n",
    "    #print('data shape',data.shape)\n",
    "    #print('labels shape',labels.shape)\n",
    "    return np.array(img, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lap_mag(channels):\n",
    "    laps = []\n",
    "    print(channels.shape)\n",
    "    for i in range(channels.shape[-1]):\n",
    "        \n",
    "        dst = cv2.Laplacian(channels[:,:,i], cv2.CV_32F , -1)\n",
    "        laps.append(dst)\n",
    "    mag = np.linalg.norm(laps, axis = 0)\n",
    "    return mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_out(input, layer_num):\n",
    "    get_layer_output = K.function([model.input], [l.output for l in model.layers][layer_num])\n",
    "    layer_out = np.array(get_layer_output(input))\n",
    "    return layer_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_arg_max(mat, window_size):\n",
    "    #Use a moving window to find local max/min in section. Determine coordinate of max pixel in image.\n",
    "    idx = []\n",
    "\n",
    "    k = int(np.floor(window_size/2))\n",
    "    print(k)\n",
    "    for i in range(k, mat.shape[0]-k):#, window_size):\n",
    "        for j in range(k, mat.shape[1]-k):#, window_size):\n",
    "\n",
    "            window = mat[i-k:i+k+1, j-k:j+k+1]\n",
    "            coords = np.argwhere(window==window.max())\n",
    "            \n",
    "            idx.extend(coords + [i-k, j-k])\n",
    "\n",
    "    return  np.unique(idx, axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints_and_descriptor(image_path):\n",
    "\n",
    "    img = load_img(image_path, [224,224])\n",
    "    img_no_proc = load_img(image_path, [224,224], preprocess=False)\n",
    "    #keypoint_coords = np.array([])\n",
    "\n",
    "\n",
    "    input_layer = get_cnn_out(img, 0)  \n",
    "\n",
    "    layer_1 = get_cnn_out(img, 1)  \n",
    "    layer_2 =  get_cnn_out(img, 2)\n",
    "\n",
    "    layer_4 =  get_cnn_out(img, 4)\n",
    "    layer_5 =  get_cnn_out(img, 5)\n",
    "\n",
    "    block_1 = lap_mag(layer_1) # +  lap_mag(layer_2)) /2\n",
    "    block_2 = lap_mag(layer_2)\n",
    "    block_4 = lap_mag(layer_4)\n",
    "    block_5 = lap_mag(layer_5)\n",
    "\n",
    "    layer_output = np.stack([layer_1, layer_2])\n",
    "    \n",
    "    pool_1 =  np.stack([get_cnn_out(img, 3)])\n",
    "    pool_2 =  np.stack([get_cnn_out(img, 6)])\n",
    "    pool_3 =  np.stack([get_cnn_out(img, 10)])[0]\n",
    "\n",
    "    keypoint_coords_1 = local_arg_max(block_1, 3)\n",
    "    keypoint_coords_2 = local_arg_max(block_2, 3)\n",
    "    #keypoint_coords_4 = local_arg_max(block_4, 3)*2\n",
    "    #keypoint_coords_5 = local_arg_max(block_5, 3)*2\n",
    "\n",
    "    keypoint_coords = np.unique(np.concatenate([keypoint_coords_1, keypoint_coords_2]),  axis=0)\n",
    "    #layer_output = np.stack([layer_1, layer_2])\n",
    "\n",
    "    k=[]\n",
    "    d=[]\n",
    "    gray = cv2.cvtColor(img_no_proc,cv2.COLOR_BGR2GRAY)\n",
    "    r = cv2.cornerHarris(gray,5,5,0.04, cv2.BORDER_ISOLATED)\n",
    "    r = cv2.dilate(r,None)\n",
    "    for row, col in keypoint_coords:\n",
    "    #print(float(row), float(col))\n",
    "        #if r[row,col]  > 0.01*np.amax(r) : #if pixel is not on edge\n",
    "\n",
    "        keypoint = cv2.KeyPoint()\n",
    "        keypoint.pt = (float(col), float(row))\n",
    "        keypoint.octave = 0\n",
    "        keypoint.size = 0\n",
    "        keypoint.response = 3\n",
    "        k.append(keypoint)\n",
    "        d0 = np.array(img_no_proc[row, col ]).flatten()\n",
    "        d1 = np.array(layer_output[:, row, col ]).flatten()\n",
    "        #d1 = d1/np.std(d1)\n",
    "        d2 = np.array(pool_1[:, round(row/2)-1, round(col/2)-1 ]).flatten()\n",
    "        #d2 = d2/np.std(d2)\n",
    "\n",
    "        d3 = np.array(pool_2[:, round(row/4)-1, round(col/4)-1 ]).flatten()\n",
    "        d4 = np.array(pool_3[:, round(row/8)-1, round(col/8)-1 ]).flatten()\n",
    "\n",
    "        dd = np.concatenate([d1, d2, d3])\n",
    "        dd = dd/np.std(dd)\n",
    "        #pca = PCA(n_components=dd.shape[0])\n",
    "        #dd = pca.fit_transform(dd.reshape(-1, 1) )\n",
    "        d.append(dd)\n",
    "\n",
    "    return np.array(k), np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startin\n",
      "(224, 224, 64)\n",
      "(224, 224, 64)\n",
      "(112, 112, 128)\n",
      "(112, 112, 128)\n",
      "1\n",
      "1\n",
      "(224, 224, 64)\n",
      "(224, 224, 64)\n",
      "(112, 112, 128)\n",
      "(112, 112, 128)\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [6.4, 4.8]\n",
    "\n",
    "data_path1= './SYS809_projet2022_sequences1/new_livre1.jpg' #'./SYS809_projet2022_sequences1/new_livre1.JPG'\n",
    "data_path2='./SYS809_projet2022_sequences1/livre2.jpg' # './SYS809_projet2022_sequences1/livre2.JPG'\n",
    "\n",
    "data_path1= './SYS809_projet2022_sequences1/magasinA-02.jpg'  #'./SYS809_projet2022_sequences1/livre1_old.JPG'\n",
    "data_path2=  './SYS809_projet2022_sequences1/magasinB-02.jpg'\n",
    "\n",
    "#sift = cv2.SIFT_create()\n",
    "print(\"Startin\")\n",
    "img_shape=[224,224]\n",
    "'''img1 = load_img(data_path1,img_shape, preprocess=False).copy()\n",
    "img2 = load_img(data_path2,img_shape, preprocess=False).copy()\n",
    "\n",
    "#plt.imshow(img1[0])\n",
    "\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)'''\n",
    "\n",
    "kp1,des1 = get_keypoints_and_descriptor(data_path1)\n",
    "kp2,des2 = get_keypoints_and_descriptor(data_path2)\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "#knnMatch retourne les 2 plus proche voisin pour chaque membre de des1\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "#Les objects DMatch contiennent index de du point-cle de ds1 match dans le champ queryIdx\n",
    "#et l'index du point-cle appartenant a des2 dans le champ trainIdx\n",
    "print(\"Done Match\")\n",
    "\n",
    "# Need to draw only good matches, so create a mask\n",
    "matchesMask = [[0,0] for i in range(len(matches))]\n",
    "print(\"len match:\", len(matches))\n",
    "\n",
    "# ratio test as per Lowe's paper,\n",
    "good = []\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < .7 * n.distance:\n",
    "        good.append(m)\n",
    "        matchesMask[i]=[1,0]\n",
    "\n",
    "draw_params = dict(matchColor = (0,255,0), #-1, #(0,255,0),\n",
    "                   singlePointColor = (0,0,0),\n",
    "                   matchesMask = matchesMask,\n",
    "                   flags = 2|4)\n",
    "\n",
    "img1 = load_img(data_path1,img_shape, preprocess=False)\n",
    "img2 = load_img(data_path2,img_shape, preprocess=False)\n",
    "img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,matches,None, **draw_params )\n",
    "\n",
    "print(\"len match:\", len(matches))\n",
    "print(\"len good:\", len(good))\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[[1,2,3,4],[3,4,5,6],[8,7,5,3],[7,5,3,2]], [[5,4,2,1],[10,11,12,13],[77,66,55,44], [88,99,66,44]] ])\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keypoint_coords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7508/1605445644.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkeypoint_coords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'keypoint_coords' is not defined"
     ]
    }
   ],
   "source": [
    "keypoint_coords"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "475d1117ccb240fef505c545958bb6f28a60dd9db01ade801a106393bc57993a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
